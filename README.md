# ğŸ¤– Self-RAG Groq Chatbot with Docling & GIST Embeddings

> A sophisticated RAG (Retrieval-Augmented Generation) chatbot implementing Self-RAG methodology with advanced PDF processing and semantic understanding capabilities powered by Groq's lightning-fast inference.

## âœ¨ Features

- ğŸ§  **Self-RAG Implementation**: Advanced retrieval-augmented generation with self-reflection and iterative refinement
- âš¡ **Groq-Powered Inference**: Ultra-fast LLM responses using Groq's optimized infrastructure
- ğŸ“„ **Smart PDF Processing**: High-quality document parsing using Docling for accurate text extraction
- ğŸ¯ **Semantic Understanding**: GIST embeddings for superior document comprehension and retrieval
- ğŸ›¡ï¸ **Rate Limiting**: Built-in intelligent rate limiting for Groq API to prevent quota exhaustion
- ğŸ–¥ï¸ **Interactive Web UI**: Clean and intuitive Streamlit interface with real-time chat
- ğŸ”„ **Document Grading**: Automatic relevance scoring and hallucination detection
- ğŸ“Š **Usage Monitoring**: Real-time API usage tracking and limit visualization

## ğŸ› ï¸ Technology Stack

### **Core Framework**
- ğŸŒŸ **Streamlit** - Interactive web application framework
- ğŸ—ï¸ **LangGraph** - Workflow orchestration and state management

### **AI/ML Components**
- ğŸš€ **Groq API** - Ultra-fast LLM inference (gemma2-9b-it model)
- ğŸ¤– **LangChain** - RAG pipeline and prompt management
- ğŸ¯ **GIST Embeddings** - Advanced semantic text embeddings
- ğŸ“š **SentenceTransformers** - Embedding model infrastructure

### **Document Processing**
- ğŸ“„ **Docling** - High-quality PDF parsing and text extraction
- âœ‚ï¸ **Semantic Chunker** - Intelligent document segmentation

### **Vector Storage**
- ğŸ—ƒï¸ **ChromaDB** - Efficient vector database for embeddings
- ğŸ” **Similarity Search** - Fast semantic document retrieval

### **Data & Utilities**
- ğŸ“‹ **Pydantic** - Data validation and structured outputs
- ğŸ”’ **Threading** - Thread-safe rate limiting
- â° **DateTime** - Time-based API quota management

## ğŸ”„ Self-RAG Workflow

```mermaid
graph TD
    A[ğŸš€ START] --> B[ğŸ” Retrieve Documents]
    B --> C[ğŸ“Š Grade Document Relevance]
    C --> D{ğŸ“‹ Relevant Docs Found?}
    
    D -->|âœ… Yes| E[ğŸ¯ Generate Answer]
    D -->|âŒ No| F[ğŸ”„ Transform Query]
    
    F --> B
    
    E --> G[ğŸ” Grade Generation Quality]
    G --> H{ğŸ¤” Quality Check}
    
    H -->|âœ… Useful & Grounded| I[ğŸ‰ END - Return Answer]
    H -->|âŒ Not Useful| F
    H -->|âš ï¸ Hallucinated| F
    
    style A fill:#ff8c00
    style I fill:#ff8c00
    style F fill:#ff8c00
    style G fill:#ff8c00
```

## ğŸš€ Quick Start

### Prerequisites
- ğŸ Python 3.12 or higher
- ğŸ”‘ Groq API key ([Get one here](https://console.groq.com/))

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/bsasidharan15/self-rag-groq-chatbot.git
cd self-rag-groq-chatbot
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Configure API Key:**
Update the API key in `app.py` at line 628, or set it as an environment variable:
```python
groq_api_key = "your_groq_api_key_here"
```

Alternatively, set as environment variable:
```bash
export GROQ_API_KEY="your_groq_api_key_here"
```

4. **Run the application:**
```bash
streamlit run app.py
```

5. **Open your browser:**
Navigate to `http://localhost:8501` to start using the chatbot! ğŸ‰

## ğŸ“– How to Use

### **Step 1: Document Upload**
- ğŸ“ Use the sidebar to upload PDF files or enter document URLs
- ğŸ“š Multiple documents supported for comprehensive knowledge base

### **Step 2: Document Processing**
- âš™ï¸ Click "Process Documents" to create the vector knowledge base
- ğŸ”„ Watch the progress as documents are parsed and embedded

### **Step 3: Interactive Chat**
- ğŸ’¬ Ask questions about your documents in the chat interface
- ğŸ§  Experience Self-RAG's intelligent retrieval and generation process

### **Step 4: Monitor Performance**
- ğŸ“Š Check API rate limits and usage in the sidebar dashboard
- âš¡ View real-time Groq API performance metrics

## ğŸ”§ Configuration

### **Model Settings**
- **LLM Model**: `gemma2-9b-it` (Groq)
- **Embedding Model**: `avsolatorio/GIST-large-Embedding-v0`
- **Fallback Model**: `sentence-transformers/all-MiniLM-L6-v2`

### **Groq API Rate Limits**
- ğŸ“ˆ **RPM**: 30 requests per minute
- ğŸš€ **TPM**: 15,000 tokens per minute  
- ğŸ“… **RPD**: 14,400 requests per day
- ğŸ’¾ **TPD**: 500,000 tokens per day

### **Self-RAG Parameters**
- **Recursion Limit**: 10 iterations max
- **Chunk Size**: Minimum 50 characters
- **Semantic Threshold**: 80th percentile breakpoint

## ğŸ—ï¸ Architecture

The application follows a modular architecture optimized for Groq's high-speed inference:

```
ğŸ“¦ Self-RAG Groq Chatbot
â”œâ”€â”€ ğŸš€ GroqLLM - High-speed API client with rate limiting
â”œâ”€â”€ ğŸ§¬ GISTEmbeddings - Semantic embedding model
â”œâ”€â”€ ğŸ“Š SelfRAGChatbot - Main orchestration class
â”œâ”€â”€ ğŸ”„ StateGraph - LangGraph workflow engine
â”œâ”€â”€ ğŸ“‹ Pydantic Models - Data validation schemas
â””â”€â”€ ğŸ–¥ï¸ Streamlit UI - Web interface components
```

## ğŸ¯ Self-RAG Process

The Self-RAG methodology ensures high-quality, grounded responses:

1. **ğŸ” Document Retrieval**: Query vector database for semantically relevant chunks
2. **ğŸ“Š Relevance Grading**: AI evaluates document relevance to user question
3. **ğŸ¯ Answer Generation**: Create response using relevant context with Groq's fast inference
4. **ğŸ” Quality Assessment**: Check for hallucinations and factual accuracy
5. **ğŸ”„ Iterative Refinement**: Retry with improved queries if quality standards not met

## ğŸ›¡ï¸ Error Handling & Reliability

- âš¡ **Rate Limit Protection**: Automatic waiting and retry logic for Groq API
- ğŸ”„ **Fallback Mechanisms**: Graceful degradation when limits exceeded  
- ğŸ› ï¸ **Recursion Prevention**: Max iteration limits to avoid infinite loops
- ğŸ“ **Comprehensive Logging**: Detailed error reporting and user feedback
- ğŸš¨ **API Health Monitoring**: Real-time Groq service status checking

## ğŸ“Š Performance Features

- âš¡ **Lightning Fast**: Groq's optimized inference for sub-second responses
- ğŸ§  **Smart Caching**: Efficient vector similarity search with ChromaDB
- ğŸ“ˆ **Scalable**: Handles large document collections efficiently
- ğŸ”„ **Adaptive**: Self-improving through iterative refinement

## ğŸ› ï¸ Development

### **Project Structure**
```
self-rag-groq-chatbot/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ LICENSE               # MIT License
â””â”€â”€ docs/                 # Additional documentation
    â”œâ”€â”€ api-reference.md
    â””â”€â”€ deployment.md
```

### **Key Dependencies**
```
streamlit>=1.28.0
langchain>=0.1.0
langgraph>=0.0.40
groq>=0.4.0
sentence-transformers>=2.2.2
chromadb>=0.4.15
docling>=1.0.0
pydantic>=2.0.0
```

## ğŸš€ Deployment

### **Local Development**
```bash
# Development mode with hot reload
streamlit run app.py --server.runOnSave true
```

### **Production Deployment**
```bash
# Using Docker
docker build -t self-rag-groq-chatbot .
docker run -p 8501:8501 self-rag-groq-chatbot

# Using Streamlit Cloud
# Connect your GitHub repo to Streamlit Cloud
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### **Contributing Guidelines**
1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Open a Pull Request

For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- ğŸš€ **Groq** for providing ultra-fast LLM inference infrastructure
- ğŸ“„ **Docling** team for excellent PDF processing capabilities
- ğŸ¯ **GIST Embeddings** for superior semantic understanding
- ğŸ—ï¸ **LangChain** community for comprehensive RAG frameworks
- ğŸŒŸ **Streamlit** for the amazing web application framework
- ğŸ§  **LangGraph** for powerful workflow orchestration

## ğŸ“ Support

- ğŸ› **Bug Reports**: [Create an issue](https://github.com/bsasidharan15/self-rag-groq-chatbot/issues)
- ğŸ’¡ **Feature Requests**: [Request a feature](https://github.com/bsasidharan15/self-rag-groq-chatbot/issues)
- ğŸ’¬ **Discussions**: [Join the conversation](https://github.com/bsasidharan15/self-rag-groq-chatbot/discussions)

## ğŸ“ˆ Roadmap

- [ ] ğŸ”„ Multi-language support
- [ ] ğŸ“Š Advanced analytics dashboard
- [ ] ğŸ”Œ Additional LLM provider integrations
- [ ] ğŸ“± Mobile-responsive UI improvements
- [ ] ğŸ¨ Customizable chat themes
- [ ] ğŸ“¡ API endpoint for external integrations

---

**Built with â¤ï¸ using cutting-edge AI technologies and Groq's blazing-fast inference**

[â­ Star this repo](https://github.com/bsasidharan15/self-rag-groq-chatbot) â€¢ [ğŸ› Report Bug](https://github.com/bsasidharan15/self-rag-groq-chatbot/issues) â€¢ [âœ¨ Request Feature](https://github.com/bsasidharan15/self-rag-groq-chatbot/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/bsasidharan15/self-rag-groq-chatbot/discussions)

[![Made with Streamlit](https://img.shields.io/badge/Made%20with-Streamlit-red?style=for-the-badge&logo=streamlit)](https://streamlit.io/)
[![Powered by Groq](https://img.shields.io/badge/Powered%20by-Groq-orange?style=for-the-badge)](https://groq.com/)
[![Python 3.12+](https://img.shields.io/badge/Python-3.12+-blue?style=for-the-badge&logo=python)](https://python.org/)
[![Apache 2.0 License](https://img.shields.io/badge/License-Apache%202.0-green?style=for-the-badge)](LICENSE)
